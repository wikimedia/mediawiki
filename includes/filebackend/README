Some notes on the FileBackend architecture.


== Introduction ==

To abstract away the differences among different types of storage media,
MediaWiki is providing an interface known as FileBackend. Any MediaWiki
interaction with stored files should thus use a FileBackend object.

Different types of backing storage media are supported (ranging from local
filesystem to distributed object stores). The types include:

* FSFileBackend (used for mounted filesystems)
* SwiftFileBackend (used for Swift or Ceph Rados+RGW object stores)
* FileBackendMultiWrite (useful for transitioning from one backend to another)

Configuration documentation for each type of backend is to be found in their
__construct() inline documentation.


== Setup ==

File backends are registered in LocalSettings.php via the global variable
$wgFileBackends. To access one of those defined backend, one would use
FileBackendStore::get( <name> ) which will bring back a FileBackend object
handle. Such handles are reused for any subsequent get() call (singleton
paradigm). The FileBackends objects are caching request calls such as file stats,
sha1 requests or TCP connection handles.

; note
: Some backends may require additional PHP extensions to be enabled or can rely on a MediaWiki extension.
This is often the case when a FileBackend subclass makes use of an upstream
client API for communicating with the backing store.


== File operations ==

The MediaWiki FileBackend API supports various operations on either files or
directories.


=== Reading ===

The following operations are supported for reading from a backend:

On files:
* stating a file for basic information (timestamp,size)
* reading a file into a string or  several files into a map of path names to strings
* downloading a file or set of files to a temporary file (on a mounted FS)
* getting the SHA1 hash of a file
* getting various properties of a file (stat information, content time, mime information, etc...)

On directories:
* get a list of files directly under a directory
* get a recursive list of files under a directory
* get a list of directories directly under a directory
* get a recursive list of directories under a directory


=== Writing, altering ===

The following operations are supported for writing or changing in the backend:

On files:
* store (copying a mounted filesystem file into storage)
* create (creating a file within storage from a string)
* copy (within storage)
* move (within storage)
* delete (within storage)
* lock/unlock (lock or unlock a file in storage)

The following operations are supported for writing directories in the backend:
* prepare (create parent container and directories for a path)
* secure (try to lock-down access to a container)
* publish (try to reverse the effects of secure)
* clean (remove empty containers or directories)


=== Invoking an operation ===

Generally, callers should use doOperations() or doQuickOperations() when doing
batches of changes, rather than making a string of single operation calls. This
makes the system tolerate high latency much better by pipelining operations
when possible.

doOperations() should be used for working on important original data, i.e. when
consistency is important. the former will only pipeline operations that do not
depend on each other. It is best if the operations that do not depend on each
other occur in consecutive groups.

doQuickOperations() is more geared toward ephemeral items that can be easily
regenerated from original data. It will always pipeline without checking for
dependencies within the operation batch.


== Locking ==

Locking is effective if and only if a proper lock manager is registered andn is
actually being used by the backend. Lock managers can be registered in
LocalSettings.php using the $wgLockManagers global configuration variable.

For object stores, locking is not generally useful for avoiding of partially
written or read objects, since most stores use Multi Version Concurrency
Control (MVCC) to avoid this.

However, locking can be important for MediaWiki when multiple operations must
be done without objects changing in the meantime.  MVCC is also a useful
pattern to use even on top of the backend interface, because operations are not
atomic, so doing complex batch file changes or changing files and updating a
database row can result in partially written "transactions". One should avoid
changing files once they have been stored, except perhaps with ephemeral data
that  s tolerant of some inconsistency.


== Object stores ==

Support for object stores (like S3/Swift) drive much of the API and design
decisions of this class, but using NTFS or POSIX filesystems works perfectly
fine. The system essentially stores "files" in "containers". For a mounted file
system as a backing store, these will just be "files" under "directories". For
an object store as a backing store, the "files" will be "objects" stored in
"containers".


== File and Object store differences ==

An advantage of objects stores is the reduced Round-Trip Times. This is
achieved by avoiding the need to create each parent directory before placing a
file somewhere. It gets worse the deeper the directory hierarchy is. Both with
object stores and file systems  using "/" in filenames will allow for the
intuitive use of directory functions. For example, creating a file in Swift
called "container/a/b/file1" will mean that:
- a "directory listing" of "container/a" will contain "b",
- and a "file listing" of "b" will contain "file1"

This means that switching from an object store to a file system and vise versa
using the FileBackend interface will generally be harmless. You must aware of
some reserves though:

* In a filesystem, you cannot have a file and a directory within the same path
  whereas it is possible in an object stores.
* Some file systems have file name length restrictions or overall path length
  restrictions that others do not. The same goes with object stores wich might
  have maximum object length or a limitation regarding the number of files
  under a container or volume.
* Latency vary among systems, certain access patterns may not be tolerable for
  certain backends but may hold up for others. Some backend subclasses use
  MediaWiki's object caching for serving stat requests, which can greatly
  reduce latency. Making sure that the backend has pipelining (see the
  "parallelize" and "concurrency" settings) enabled can also combat latency in
  batch operation scenarios.
