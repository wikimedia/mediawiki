/*!
\ingroup JobQueue
\page jobqueue_design Job queue design

Notes on the Job queuing system architecture.

\section intro Introduction

The data model consist of the following main components:

* The Job object represents a particular deferred task that happens in the
  background.
* The JobQueue object represents a particular queue of jobs of a certain type.
  For example there may be a queue for email jobs and a queue for squid purge
  jobs.

Each job type has its own queue and is associated to a storage medium. One
queue might save its jobs in redis while another one uses would use a database.

Storage medium are defined in a queue class. Before using it, you must
define in $wgJobTypeConf a mapping of the job type to a queue class.

The factory class JobQueueGroup provides helper functions:
- getting the queue for a given job
- route new job insertions to the proper queue

The following queue classes are available:
* JobQueueDB (stores jobs in the `job` table in a database)

All queue classes support some basic operations (though some may be no-ops):
* enqueueing a batch of jobs
* dequeueing a single job
* acknowledging a job is completed
* checking if the queue is empty

Job queues in MediaWiki can be generalized as priority queues with an undefined
priority ordering.  Some queue classes (like JobQueueDB) may dequeueue jobs in
random order while a queue that uses redis might dequeue jobs in exact FIFO
order. Callers should thus not assume jobs are executed in FIFO order.

Also note that not all queue classes will have the same reliability guarantees.
In-memory queues may loose data when restarted depending on snapshot and
journal settings (including disk syncing).  Some queue types may totally remove
jobs when dequeued while leaving the ack() function as a no-op; if a job is
dequeued by a job runner, which crashes before completion, the job will be
lost. Some jobs, like purging squid caches after a template change, may not
require durable queues, were as other jobs might be more important.

Callers should also try to make jobs maintain correctness when executed twice.
This is useful for queues that actually implement ack(), since they may recycle
dequeued but un-acknowledged jobs back into the queue to be attempted again. If
a runner dequeues a job, does it, but then crashes before calling ack(), the
job may eventually get done a second time. A pathological case would be if a
bug causes the problem to systematically keep repeating. This problem is
trickier to solve and more harmful for email jobs, for example. For such jobs,
it might be useful to use a queue that does not retry jobs.
